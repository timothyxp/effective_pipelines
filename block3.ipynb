{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d63306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-07 13:47:38--  https://www.dropbox.com/s/tc1qo73rrm3gt3m/CARVANA.zip\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.18, 2620:100:6026:18::a27d:4612\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/tc1qo73rrm3gt3m/CARVANA.zip [following]\n",
      "--2022-03-07 13:47:38--  https://www.dropbox.com/s/raw/tc1qo73rrm3gt3m/CARVANA.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucbe7aeba3b62c4d346ece644953.dl.dropboxusercontent.com/cd/0/inline/BhAv_omEPaOc0AnpPe6-LnXmrTrkSKTiXlde0ulfzDxpmSZ516DVmzaadVIDfjED7GbSuJCTRiLaB7Wtk1P3sTnc03CL6ZQHCuMu991StcrEMPVYEQR1VUBi5tbfkGBWtxKvnfDVSkgFnpRfK2ojK7d_/file# [following]\n",
      "--2022-03-07 13:47:39--  https://ucbe7aeba3b62c4d346ece644953.dl.dropboxusercontent.com/cd/0/inline/BhAv_omEPaOc0AnpPe6-LnXmrTrkSKTiXlde0ulfzDxpmSZ516DVmzaadVIDfjED7GbSuJCTRiLaB7Wtk1P3sTnc03CL6ZQHCuMu991StcrEMPVYEQR1VUBi5tbfkGBWtxKvnfDVSkgFnpRfK2ojK7d_/file\n",
      "Resolving ucbe7aeba3b62c4d346ece644953.dl.dropboxusercontent.com (ucbe7aeba3b62c4d346ece644953.dl.dropboxusercontent.com)... 162.125.70.15, 2620:100:6026:15::a27d:460f\n",
      "Connecting to ucbe7aeba3b62c4d346ece644953.dl.dropboxusercontent.com (ucbe7aeba3b62c4d346ece644953.dl.dropboxusercontent.com)|162.125.70.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/BhB3nOvmHoUmjXPPCcGraqRERPQE0sFQsQbPa7s3ql7QwF7M2Z417_-X-pR0z-FCZSNvuC-fR2AUqj9Q_AbziY3TDZLO0kPkTtbi5a2Pr4A5lV73ll6IxcWu7pVtq2_jmqOKGjuf4HDJfk8EA6Gl_nA1MyixXcGyI1L6xSRT_rXdsYdXdUo51g1rrEL4-aFBsnT9UyT5V8vnmLQ8ZpURGiByhYMGoBHxGAsG9uhMI-aa4Ae22iCdFbDx34eQMMVZbkfYrNt6h5fnMTLDqiJv-D3P3uOb6pTLxELPKNX97aL6m06fczmQlgt5xewVcxFYqct_P1ZRj3B9oZd3pnYDnO_Z9y7QBhQt5o_6Zc1MyE1pEY_fF2NP7cVtWSZ-WitXGTA/file [following]\n",
      "--2022-03-07 13:47:39--  https://ucbe7aeba3b62c4d346ece644953.dl.dropboxusercontent.com/cd/0/inline2/BhB3nOvmHoUmjXPPCcGraqRERPQE0sFQsQbPa7s3ql7QwF7M2Z417_-X-pR0z-FCZSNvuC-fR2AUqj9Q_AbziY3TDZLO0kPkTtbi5a2Pr4A5lV73ll6IxcWu7pVtq2_jmqOKGjuf4HDJfk8EA6Gl_nA1MyixXcGyI1L6xSRT_rXdsYdXdUo51g1rrEL4-aFBsnT9UyT5V8vnmLQ8ZpURGiByhYMGoBHxGAsG9uhMI-aa4Ae22iCdFbDx34eQMMVZbkfYrNt6h5fnMTLDqiJv-D3P3uOb6pTLxELPKNX97aL6m06fczmQlgt5xewVcxFYqct_P1ZRj3B9oZd3pnYDnO_Z9y7QBhQt5o_6Zc1MyE1pEY_fF2NP7cVtWSZ-WitXGTA/file\n",
      "Reusing existing connection to ucbe7aeba3b62c4d346ece644953.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 461489772 (440M) [application/zip]\n",
      "Saving to: ‘CARVANA.zip’\n",
      "\n",
      "CARVANA.zip         100%[===================>] 440.11M  13.7MB/s    in 35s     \n",
      "\n",
      "2022-03-07 13:48:16 (12.4 MB/s) - ‘CARVANA.zip’ saved [461489772/461489772]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download and unpack data\n",
    "!wget https://www.dropbox.com/s/tc1qo73rrm3gt3m/CARVANA.zip  # Carvana dataset\n",
    "!unzip -q CARVANA.zip\n",
    "!rm -rf ./train/.DS_Store\n",
    "!rm -rf ./train_masks/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb2d6cf-3694-47a9-96b2-34e695d1ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef310df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "# code sourse: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from transformer import generate_square_subsequent_mask, TransformerModel\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c248c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = WikiText2(split=\"train\")\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# train_iter was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Args:\n",
    "        data: Tensor, shape [N]\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape [N // bsz, bsz]\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
    "val_data = batchify(val_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1285366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
    "        target has shape [seq_len * batch_size]\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc06e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.2  # dropout probability\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5964f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    i = 0\n",
    "    for batch in trange(0, train_data.size(0) - 1, bptt, desc=\"Epoch progress: \"):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        batch_size = data.size(0)\n",
    "        if batch_size != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:batch_size, :batch_size]\n",
    "        with record_function(\"forward\"):\n",
    "            output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        # feel free to comment out this \n",
    "        optimizer.zero_grad()\n",
    "        with record_function(\"backward\"):\n",
    "            loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                  f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                  f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\")\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        i += 1\n",
    "            \n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            batch_size = data.size(0)\n",
    "            if batch_size != bptt:\n",
    "                src_mask = src_mask[:batch_size, :batch_size]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64160a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c6076009ee4ef0a332eab7ab213447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/2929 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 24.74 | loss  1.53 | ppl     4.62\n",
      "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch  4.31 | loss  0.68 | ppl     1.97\n",
      "| epoch   1 |  4200/ 2928 batches | lr 5.00 | ms/batch  4.51 | loss  0.46 | ppl     1.58\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 1\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    with profile(activities=[\n",
    "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        train(model)\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    val_ppl = math.exp(val_loss)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print(\"-\" * 89)\n",
    "    print(f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "          f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\")\n",
    "    print(\"-\" * 89)\n",
    "\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         best_model = copy.deepcopy(model)\n",
    "\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9156d-7268-40f0-9538-76aa01d78270",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = prof.key_averages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09aae7b5-667f-4023-a5ca-cb7a6d05b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transformer_stats_cpu.txt\", \"w\") as f:\n",
    "    f.write(stat.table(sort_by=\"cpu_time_total\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83979be6-0228-4af3-baf0-1bd389b7c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transformer_stats_cuda.txt\", \"w\") as f:\n",
    "    f.write(stat.table(sort_by=\"cuda_time_total\", row_limit=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
